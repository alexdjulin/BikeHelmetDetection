{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmRWuF3hrt8_"
      },
      "source": [
        "# Bike Helmet Detection - Training Notebook\n",
        "\n",
        "In this notebook we will fine-tune YOLOv8n on a public dataset of bike drivers wearing or not wearing a helmet.\n",
        "\n",
        "[Kaggle Notebook](https://www.kaggle.com/code/alexandredj/bikehelmetdetection-yolov8n-training) | [Google Colab Notebook](https://colab.research.google.com/drive/1KGJ68orNqPCK3llccBD6_8MmcEXA1As3)\n",
        "\n",
        "![image13_finetuned.png](readme/image13_finetuned.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rti4rp1ItWke"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZfDOwPBoQqW"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ3GHRDh21Yo"
      },
      "source": [
        "# Module imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHbL8rtS2zft"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "import random\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gOkPuH21or0"
      },
      "source": [
        "# Project paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1BVzWho1n3c"
      },
      "outputs": [],
      "source": [
        "project_dir = '/content/'\n",
        "dataset_dir = os.path.join(project_dir, 'dataset')\n",
        "\n",
        "images_dir = os.path.join(dataset_dir, \"images\")\n",
        "annotations_dir = os.path.join(dataset_dir, \"annotations\")\n",
        "labels_dir = os.path.join(dataset_dir, \"labels\")\n",
        "\n",
        "train_img_dir = os.path.join(dataset_dir, \"train\", \"images\")\n",
        "train_labels_dir = os.path.join(dataset_dir, \"train\", \"labels\")\n",
        "val_img_dir = os.path.join(dataset_dir, \"val\", \"images\")\n",
        "val_labels_dir = os.path.join(dataset_dir, \"val\", \"labels\")\n",
        "test_img_dir = os.path.join(dataset_dir, \"test\", \"images\")\n",
        "test_videos_dir = os.path.join(dataset_dir, \"test\", \"videos\")\n",
        "\n",
        "models_dir = os.path.join(project_dir, \"models\")\n",
        "predict_dir = os.path.join(project_dir, \"predict\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXVNKlYUDXdw"
      },
      "source": [
        "# Check hardware if training on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6r3Ar8O2O7F"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4zYx3WYv7rw"
      },
      "source": [
        "# Download Helmet Detection Dataset from Kaggle\n",
        "\n",
        "We are downloading and unzipping the [Helmet Detection](https://www.kaggle.com/datasets/andrewmvd/helmet-detection) dataset from kaggle. For this, you need to create a folder in your drive and add the path to the environment.  \n",
        "\n",
        "The dataset will be downloaded as a zip, we unzip it then in the dataset folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22Eghlhkwi29"
      },
      "outputs": [],
      "source": [
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = dataset_dir\n",
        "\n",
        "if not os.path.isdir(annotations_dir) and not os.path.isdir(images_dir):\n",
        "    # download dataset\n",
        "    !kaggle datasets download -d andrewmvd/helmet-detection\n",
        "    # unzip dataset\n",
        "    filepath = '/content/helmet-detection.zip'\n",
        "\n",
        "    with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "        zip_ref.extractall(dataset_dir)\n",
        "else:\n",
        "    print('Annotations and images folder already exist - Skip unzipping dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a397E8jt0nPE"
      },
      "source": [
        "# Parse XML and preview dataset images with bounding box\n",
        "\n",
        "Load a random image from the dataset, parse bounding box information and draw it on image.\n",
        "\n",
        "Green: With Helmet  \n",
        "Red: Without Helmet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rf9QM3m0pdD"
      },
      "outputs": [],
      "source": [
        "def parse_xml(xml_file):\n",
        "    '''\n",
        "    Parse the XML file and extract image information and bounding boxes\n",
        "\n",
        "    Args:\n",
        "        xml_file: str: path to the XML file\n",
        "\n",
        "    Return:\n",
        "        image_name: str: name of the image file\n",
        "        image_shape: tuple: shape of the image\n",
        "        labels_and_bboxes: list: list of tuples containing labels and bounding boxes\n",
        "    '''\n",
        "\n",
        "    # Parse the XML file\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Extract image information\n",
        "    image_name = root.find('filename').text\n",
        "    width = int(root.find('size/width').text)\n",
        "    height = int(root.find('size/height').text)\n",
        "    depth = int(root.find('size/depth').text)\n",
        "    image_shape = width, height, depth\n",
        "\n",
        "    labels_and_bboxes = []\n",
        "\n",
        "    # Loop through each object in the XML\n",
        "    for obj in root.findall('object'):\n",
        "        # Extract label and bounding box coordinates for each object\n",
        "        label = obj.find('name').text\n",
        "        xmin = int(obj.find('bndbox/xmin').text)\n",
        "        ymin = int(obj.find('bndbox/ymin').text)\n",
        "        xmax = int(obj.find('bndbox/xmax').text)\n",
        "        ymax = int(obj.find('bndbox/ymax').text)\n",
        "\n",
        "        # Append label and bounding box to the list\n",
        "        labels_and_bboxes.append((label, (xmin, ymin, xmax, ymax)))\n",
        "\n",
        "    return image_name, image_shape, labels_and_bboxes\n",
        "\n",
        "def draw_bounding_boxes(img_file, labels_and_bboxes):\n",
        "    '''\n",
        "    Draw bounding boxes on the image\n",
        "\n",
        "    Args:\n",
        "        img_file: str: path to the image file\n",
        "        labels_and_bboxes: list: list of tuples containing labels and bounding boxes\n",
        "    '''\n",
        "    # Load the image\n",
        "    image = cv2.cvtColor(cv2.imread(img_file), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Draw bounding boxes on the image\n",
        "    for label, bbox in labels_and_bboxes:\n",
        "        xmin, ymin, xmax, ymax = bbox\n",
        "        rgb_color = (0, 255, 0) if label == 'With Helmet' else (255, 0, 0)\n",
        "\n",
        "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), rgb_color, 2)\n",
        "        cv2.putText(image, label, (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.35, rgb_color, 1)\n",
        "\n",
        "    # Display the image with bounding boxes\n",
        "    plt.axis(False)\n",
        "    plt.title(os.path.split(img_file)[-1], y=-0.1)\n",
        "    plt.imshow(image)\n",
        "\n",
        "def get_random_img_xml():\n",
        "    '''\n",
        "    Get a random image and its corresponding XML file\n",
        "\n",
        "    Return:\n",
        "        img_file: str: path to the image file\n",
        "        xml_file: str: path to the XML file\n",
        "    '''\n",
        "\n",
        "    # pick a random image from the dataset\n",
        "    img_name = random.choice(os.listdir(images_dir))\n",
        "    # img_name = 'BikesHelmets99.png'\n",
        "    img_file = os.path.join(images_dir, img_name)\n",
        "    xml_file = os.path.join(annotations_dir, img_name[:-4]+'.xml')\n",
        "\n",
        "    return img_file, xml_file\n",
        "\n",
        "\n",
        "# Main\n",
        "img_file, xml_file = get_random_img_xml()\n",
        "image_name, image_shape, labels_and_bboxes = parse_xml(xml_file)\n",
        "draw_bounding_boxes(img_file, labels_and_bboxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5pNpOduyKQY"
      },
      "source": [
        "# Convert input labels\n",
        "The dataset provides PNG images and XML labels using the Pascal VOC format.  \n",
        "\n",
        "Example:\n",
        "\n",
        "```xml\n",
        "<annotation>\n",
        "    <folder>images</folder>\n",
        "    <filename>BikesHelmets1.png</filename>\n",
        "    <size>\n",
        "        <width>400</width>\n",
        "        <height>300</height>\n",
        "        <depth>3</depth>\n",
        "    </size>\n",
        "    <segmented>0</segmented>\n",
        "    <object>\n",
        "        <name>With Helmet</name>\n",
        "        <pose>Unspecified</pose>\n",
        "        <truncated>0</truncated>\n",
        "        <occluded>0</occluded>\n",
        "        <difficult>0</difficult>\n",
        "        <bndbox>\n",
        "            <xmin>161</xmin>\n",
        "            <ymin>0</ymin>\n",
        "            <xmax>252</xmax>\n",
        "            <ymax>82</ymax>\n",
        "        </bndbox>\n",
        "    </object>\n",
        "</annotation>\n",
        "```\n",
        "\n",
        "However, Yolo requires a different label format as input. For each image, a txt file should list the classes and the bounding boxes top left and bottom right points, normalized btw 0 and 1.\n",
        "\n",
        "{class} {bbox x1} {bbox y1} {bbox x2} {bbox y2}\n",
        "\n",
        "```\n",
        "# Example:\n",
        "1 0.51625 0.13666666666666666 0.2275 0.2733333333333333\n",
        "```\n",
        "\n",
        "Let's generate our text labels from the xml files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSuMqZANz8k0"
      },
      "outputs": [],
      "source": [
        "def create_labels(xml_dir, labels_dir):\n",
        "    '''\n",
        "    Create labels for each image in the dataset. Ignore image if invalid bboxes (coordinates out of image shape)\n",
        "\n",
        "    Args:\n",
        "        xml_dir: str: path to the directory containing the annotation xml files\n",
        "        labels_dir: str: path to the directory where the labels will be saved\n",
        "    '''\n",
        "\n",
        "    # browse through annotation xml files and extract the class and bounding box coordinates\n",
        "    os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "    annotations = [file for file in os.listdir(xml_dir) if file.lower().endswith('.xml')]\n",
        "\n",
        "    count = 0\n",
        "    ignored = 0\n",
        "\n",
        "    for xml_file in annotations:\n",
        "\n",
        "        image_name, image_shape, labels_and_bboxes = parse_xml(os.path.join(xml_dir, xml_file))\n",
        "\n",
        "        # save label and bbox to a text file with same name than image file\n",
        "        txt_file = os.path.join(labels_dir, xml_file.replace('.xml', '.txt'))\n",
        "\n",
        "        file_corrupt = False\n",
        "\n",
        "        with open(txt_file, 'w') as f:\n",
        "\n",
        "            for label, bbox in labels_and_bboxes:\n",
        "\n",
        "                # get label\n",
        "                label = 1 if label == 'With Helmet' else 0\n",
        "\n",
        "                # compute bounding box center, width and height from bbox coordinates\n",
        "                x_center = (bbox[0] + bbox[2]) / 2\n",
        "                y_center = (bbox[1] + bbox[3]) / 2\n",
        "                width = bbox[2] - bbox[0]\n",
        "                height = bbox[3] - bbox[1]\n",
        "\n",
        "                # normalize all values between 0 and 1\n",
        "                x_center /= image_shape[0]\n",
        "                y_center /= image_shape[1]\n",
        "                width /= image_shape[0]\n",
        "                height /= image_shape[1]\n",
        "\n",
        "                # check if values are within the range 0 and 1\n",
        "                if x_center > 1 or y_center > 1 or width > 1 or height > 1:\n",
        "                    file_corrupt = True\n",
        "                    break\n",
        "\n",
        "                f.write(f\"{label} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "        # delete corrupted files (values don't make any sense)\n",
        "        if file_corrupt:\n",
        "            ignored += 1\n",
        "            f.close()\n",
        "            os.remove(txt_file)\n",
        "            continue\n",
        "\n",
        "        print(f\"\\rImage: {image_name}     \", end='', flush=True)\n",
        "        count += 1\n",
        "\n",
        "\n",
        "    print(f\"\\n>> {count} labels created | {ignored} images ignored\")\n",
        "\n",
        "# Main\n",
        "create_labels(annotations_dir, labels_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNc-Wk445t7F"
      },
      "source": [
        "# Create Train/Validation sets\n",
        "Split images and labels into a training and validation sets with an 80/20 ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch-hwznO54ZK"
      },
      "outputs": [],
      "source": [
        "def create_train_val_split():\n",
        "    '''\n",
        "    Create a train and val split of the images/labels.\n",
        "    '''\n",
        "\n",
        "    # make sure target dirs exist\n",
        "    for dir in [train_img_dir, val_img_dir, train_labels_dir, val_labels_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    # copy images randomly to train and val folders using 80/20 split\n",
        "    images = [img[:-4] for img in os.listdir(images_dir)]\n",
        "    random.shuffle(images)\n",
        "    split = int(0.8 * len(images))\n",
        "\n",
        "    count_total = len(images)\n",
        "    count_train = 0\n",
        "    count_val = 0\n",
        "    count_ignored = 0\n",
        "\n",
        "    for i in range(len(images)):\n",
        "\n",
        "        # check if label exists (some images are corrupted and don't have a label file)\n",
        "        if not os.path.exists(os.path.join(labels_dir, f\"{images[i]}.txt\")):\n",
        "            count_ignored += 1\n",
        "            count_total -= 1\n",
        "            continue\n",
        "\n",
        "        if i < split:\n",
        "            shutil.copy(os.path.join(images_dir, f\"{images[i]}.png\"), train_img_dir)\n",
        "            shutil.copy(os.path.join(labels_dir, f\"{images[i]}.txt\"), train_labels_dir)\n",
        "            count_train += 1\n",
        "        else:\n",
        "            shutil.copy(os.path.join(images_dir, f\"{images[i]}.png\"), val_img_dir)\n",
        "            shutil.copy(os.path.join(labels_dir, f\"{images[i]}.txt\"), val_labels_dir)\n",
        "            count_val += 1\n",
        "\n",
        "        count_total -= 1\n",
        "\n",
        "        print(f\"\\rImages: {count_total} >> Train: {count_train} | Val: {count_val} | Ignored: {count_ignored}     \", end='', flush=True)\n",
        "\n",
        "# Main\n",
        "create_train_val_split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6JMdI6VoqIV"
      },
      "source": [
        "# Generate the training config file\n",
        "To initiate training, yolo requires a yaml file containing the paths to our train and validation sets, as well as our output classes. Let's generate it first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apbN1XKVCqs-"
      },
      "outputs": [],
      "source": [
        "config_file_path = f'{dataset_dir}/config.yaml'\n",
        "\n",
        "config_file_contents = f'''path: {dataset_dir}  # root dir\n",
        "train: train/images  # train dir\n",
        "val: val/images  # val dir\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: without helmet\n",
        "  1: with helmet\n",
        "'''\n",
        "\n",
        "with open(config_file_path, 'w') as f:\n",
        "    f.write(config_file_contents)\n",
        "\n",
        "print(f\"Config file written successfully at location {config_file_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04AvOpA5DkGw"
      },
      "source": [
        "# Train the model\n",
        "You need to chose a pre-trained model to start from, you will get better results than training it from scratch.  \n",
        "Pick a version from [Ultralytics GitHub](https://github.com/ultralytics/ultralytics).  \n",
        "You can simply enter its name below, it will be downloaded automatically before training.  \n",
        "Below we are fine-tuning YOLOv8n pre-trained on the COCO dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vy7iRsJ1opBQ"
      },
      "outputs": [],
      "source": [
        "# deactivate WandDB if you don't wanna use it\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "\n",
        "# Load a Yolo8 model, we will use the nano version\n",
        "if not os.path.isfile(config_file_path):\n",
        "    raise FileNotFoundError(f'Config yaml file not found at location {config_file_path}.')\n",
        "\n",
        "# Base model to fine-tune\n",
        "yolo = YOLO('yolov8n.pt')  # default, pre-trained on the Coco dataset\n",
        "\n",
        "yolo.train(\n",
        "    data=config_file_path,\n",
        "    epochs=100,  # aim for at least 100 epochs\n",
        "    patience=20,  # EarlyStopping\n",
        "    batch=-1,  # automatic batch size\n",
        "    save_period=10,  # save model every 10 epochs\n",
        "    dropout=0.2,  # add some dropout to reduce overfitting\n",
        "    plots=True  # plot results\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pIWQlS9HIsV"
      },
      "source": [
        "# Validate model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2qEKHR3Ac5e"
      },
      "outputs": [],
      "source": [
        "valid_results = yolo.val()\n",
        "print(valid_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OixT9nhnGh6o"
      },
      "source": [
        "# Testing the model on a picture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyJ8EYKDGi5F"
      },
      "outputs": [],
      "source": [
        "# load latest model\n",
        "model = YOLO(os.path.join(models_dir, 'best_260424_0028.pt'))\n",
        "\n",
        "# load random image\n",
        "img_file, _ = get_random_img_xml()\n",
        "\n",
        "# predict on image and save result\n",
        "results = model.predict(source=img_file, classes=[0, 1], save=True, conf=0.5)\n",
        "\n",
        "for result in results:\n",
        "\n",
        "    # save image\n",
        "    os.makedirs(predict_dir, exist_ok=True)\n",
        "    img_pred = os.path.join(predict_dir, os.path.split(img_file)[-1])\n",
        "    result.save(img_pred)\n",
        "\n",
        "    # load and display the image with the predicted bounding boxes\n",
        "    image = Image.open(img_pred)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxh7EFgxGlqG"
      },
      "source": [
        "# Testing the model on webcam\n",
        "\n",
        "Grab your helmet and plug-in your webcam, let's try our prediction model on ourselves!  \n",
        "This section won't work on kaggle, download your model and test it locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTf0U75ZGudg"
      },
      "outputs": [],
      "source": [
        "# load latest model\n",
        "model = YOLO(os.path.join(models_dir, 'best_260424_0028.pt'))\n",
        "\n",
        "# Set webcam as source and set resolution\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3, 640)\n",
        "cap.set(4, 480)\n",
        "\n",
        "# set webcam fps\n",
        "cap.set(cv2.CAP_PROP_FPS, 15)\n",
        "\n",
        "# Load my model\n",
        "model = YOLO(f'{models_dir}/best_260424_0028.pt')\n",
        "\n",
        "while cap.isOpened():\n",
        "\n",
        "    # load and flip current frame\n",
        "    success, frame = cap.read()\n",
        "    frame = cv2.flip(frame, 1)\n",
        "\n",
        "    if success:\n",
        "        # track on frame and plot result\n",
        "        results = model.track(frame, verbose=False, conf=0.1)\n",
        "        frame = results[0].plot()\n",
        "        cv2.imshow(\"Webcam Tracking\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPX5l19HGwi_"
      },
      "source": [
        "# That's it!\n",
        "You can now download your fine-tuned YOLOv8 model and use it to predict on images/webcam/videos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
